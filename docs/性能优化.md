单次的定义：<br />本机启动 ETCD、Redis、MySQL 和 RabbitMQ<br />服务端和客户端都在本地<br />群成员总数：500 人<br />在线人数：300 人<br />每秒发送消息数量：100次<br />发送消息次数：1次<br />响应消息数量：3 0000次<br />丢失消息数量：0条<br />Message 表数量总数：5 0000条<br />总耗时：3.5s -> 0.2s<br />优化目的：降低消息推送延迟
<a name="wvaQM"></a>
### 服务端执行流程
群聊为例：<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/2518584/1681127942305-70edc6f4-8b61-4a40-968e-bd4f97f761ac.png#averageHue=%23fafafa&clientId=u3911ca04-3ca5-4&from=paste&height=606&id=ue5664aba&name=image.png&originHeight=909&originWidth=1311&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=118667&status=done&style=none&taskId=u269aabf1-ee75-4f64-9132-b41e2908f9e&title=&width=874)

1. Server 启动时，启动 worker pool
2. Client 请求建立连接，Server 为其创建 read 和 write 协程
3. Client 发送消息，read 读取并解析消息，根据消息类型赋予不同的路由函数，发送给 worker pool 等待调度业务层执行
4. 业务层执行实际路由消息，如果是群聊消息发送：
   1. 给自己发送一条消息（获取 seqId 和落库 Message 记录，但是不进行推送）
   2. 根据 groupId 从 MySQL 中获取群成员信息
   3. 验证发送者是否属于群聊
   4. 对于每个除发送者之外的群成员：
      1. 从 MySQL 获取该用户的 seqId（select seq where userId = ? and object_id = ? for update）
      2. 消息携带刚刚获取的 seqId 落库
      3. 组装下行消息进行推送
      4. 查询用户是否在线（用户通过 websocket 进行 Login 时，接入层本地存储 userId:conn 的映射，Redis 存储该 userId:RPC address 的映射），如果用户不在线，返回
      5. 查询是否用户的长连接是否在本地，如果在本地，直接进行本地推送
      6. RPC 服务提供接入层消息投递接口，通过 Redis 中 userId 映射的 RPC addr 获取到 gRPC 连接后调用 RPC 方法进行消息投递
<a name="pwnfs"></a>
### 思路1：缓存
应用缓存带来的问题：

1. 缓存自身的问题
2. 数据一致性和可用性问题

1. 创建群聊时，将群组信息存入 Redis（群组相关功能：增、删、改）
2. user 的 seqId 使用 Redis incr（后续优化可以使用预分配中间层，思想是直接使用内存作为缓存）
<a name="N430m"></a>
### 思路2：批处理

1. 集中获取用户的 seqId，为了保证顺序性，使用 lua 脚本，批次进行处理，一次最多执行 1k 个用户的 incr 脚本
2. 批量消息落库，每次落库 500 个对象
3. 消息下发时，之前都是先查用户是否在线，在哪个网关地址，再单独投递。群聊场景下，直接将全部消息投递给所有长连接网关，让它本地查找哪些用户在线，在线就进行推送，需要引入 ETCD 做服务注册
4. 消息收发过于频繁，发送消息时，暂存 buffer，当 buffer 数量满足或者到间隔时间时间，打包发送 buffer 中的数据，提高整体吞吐但是单条消息延迟上升

<a name="yISy8"></a>
### 思路3：异步处理
异步处理带来的问题：系统复杂度上升

1. 消息推送不必等到消息落库后再进行，消息落库可以异步，引入 MQ 来做
2. 消息推送是推送给不同客户端，可以异步处理，但是需要限制并发数量，比如 5 个

<a name="dJHEy"></a>
### 思路4：优化数据结构
带来的问题：系统复杂性上升

1. 场景本身：读多写少 map+mutex VS sync.Map（读多写少场景性能好） VS concurrent-map（分段锁）
2. json -> proto  10倍性能提升
3. 推送后使用时间轮替代原来的 time.NewTicker（四叉树），增删 O(LogN) -> 增删 O(1)，损失精度
4. 接入层 I/O 多路复用（其实已经算优化系统架构了）

<a name="Idm4O"></a>
### 思路5：池化

1. 协程池
2. 连接池


参考：

1. [企业微信的IM架构设计揭秘：消息模型、万人群、已读回执、消息撤回等](http://www.52im.net/thread-3631-1-1.html)
2. [从3s到25ms！看看人家的接口优化技巧，确实很优雅！](https://mp.weixin.qq.com/s/oMStgpD_5vFsBEt-Huq8zQ)
3. [zinx时间轮实现](https://github.com/aceld/zinx/blob/3d5c30bf15f00cf7b668115d118aec0dcdd5294e/ztimer/timerscheduler.go)